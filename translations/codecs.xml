<?xml version="1.0" encoding="Latin-1"?>
<target>3</target>
<categoria>Il file system</categoria><!-- # tag <descrizione> contiene le voci per la tabella di riepilogo iniziale -->
<!-- tag <testo_normale> contiene il testo normale dell'articolo -->
<!-- tag <titolo_2> contiene il testo per l'intestazione di un paragrafo -->
<!-- tag <py_code> contiene il testo che rappresenta delle istruzioni python -->
<!-- tag <py_output> contiene il testo che rappresenta l'outpu di uno script python -->
<documento_tradotto>
<titolo_1>
codecs - Codifica e Decodifica di Stringhe
</titolo_1>
<descrizione>
Codificatori e decodificatori per la conversione di testo tra diverse rappresentazioni

</descrizione>
<testo_normale>
Il modulo <strong>codecs</strong> fornisce flussi e interfacce file per trascodificare dati. E' più comunemente usato per lavorare con il testo Unicode, ma sono anche disponibili altre codifiche per altri scopi.
</testo_normale>
<titolo_2>
Elementi di Unicode
</titolo_2>
<testo_normale>
CPython 3.x distingue tra testo e stringhe di byte. Istanze <code>bytes</code> usano una sequenza di valori di 8 bit mentre le stringhe <code>str</code> sono gestite internamente come sequenza di code point (un valore numerico compreso nell'intervallo dei valori numerici disponibili per la codifica dei caratteri - n.d.t). I valori dei code point sono salvati come sequenza di 2 o 4 byte ciascuno, a seconda delle opzioni fornite quando Python è stato compilato.
</testo_normale>
<testo_normale>
Quando vengono stampati valori <code>str</code>, essi sono codificati usando uno dei parecchi schemi standard in modo che la sequenza di byte possa essere ricostruita corrispondendo alla stessa stringa di testo successivamente. I byte del valore codificato non sono necessariamente gli stessi dei code point, e la codifica definisce un modo per trascodificare i due insiemi di valori. La lettura di valori Unicode richiede anche la conoscenza della codifica in modo che i byte in arrivo possano essere convertiti nella rappresentazione interna usata dalla classe <code>unicode</code>.
</testo_normale>
<testo_normale>
Le codifiche più comuni per i linguaggi occidentali sono <code>UTF-8</code> e <code>UTF-16</code>, le quali usano rispettivamente sequenze di valori di uno o due byte per rappresentare ciascun code point. Altre codifiche possono essere più efficaci per conservare linguaggi dove la maggior parte dei caratteri sono rappresentati da code point che non possono essere compresi in due byte.
</testo_normale>
<titolo_2>
Codifiche
</titolo_2>
<testo_normale>
Il modo migliore per capire le codifiche è osservare le diverse serie di byte prodotte codificando la stessa stringa in modi diversi. Gli esempi seguenti usano questa funzione per formattare i byte della stringa per facilitarne la lettura.
</testo_normale>
<py_code>
# codecs_to_hex.py
</py_code>
<testo_normale>
La funzione usa <code>binascii</code> per ottenere la rappresentazione esadecimale dei byte della stringa in input, poi viene inserito uno spazio tra ogni <code>nbytes</code> byte prima di ritornare il valore.
</testo_normale>
<py_output>
$ python3 codecs_to_hex.py
</py_output>
<testo_normale>
Il primo esempio di codifica inizia stampando il testo <code>'français'</code> usando la rappresentazione raw della classe <code>unicode</code>, seguito dal nome di ciascun carattere dal database Unicode. Le successive due righe codificano la stringa rispettivamente in <code>UTF-8</code> e <code>UTF-16</code> e mostra i valori esadecimali risultanti dalla codifica.
</testo_normale>
<py_code>
# codecs_encodings.py
</py_code>
<testo_normale>
Il risultato della codifica di un oggetto <code>str</code> è un oggetto <code>bytes</code>.
</testo_normale>
<py_output>
$ python3 codecs_encodings.py
</py_output>
<testo_normale>
Data una sequenza di byte codificati come istanza di <code>bytes</code>, il metodo <code>decode()</code> li trascodifica in code point e ritorna la sequenza come istanza di <code>str</code>.
</testo_normale>
<py_code>
# codecs_decode.py
</py_code>
<testo_normale>
La scelta della codifica usata non cambia il tipo di risultato.
</testo_normale>
<py_output>
$ python3 codecs_decode.py
</py_output>
<titolo_2>
Lavorare con i file
</titolo_2>
<testo_normale>
Codificare e decodificare stringhe è particolarmente importante quando si ha a che fare con operazioni di I/O. A prescindere dal dover scrivere su un file, un socket od un altro canale, i dati devono usare l'opportuna codifica. In generale tutti i dati di testo devono essere decodificati dalla propria rappresentazione in byte in fase di lettura e codificati dai propri valori interni verso una rappresentazione specifica in fase di scrittura. Un programma può esplicitamente codificare e decodificare dati, ma a seconda della codifica usata può essere non triviale determinare se sono stati letti byte a sufficienza per decodificare interamente i dati. codecs fornisce classi per gestire la codifica e la decodifica dei dati, in modo che le applicazioni non debbano compiere questo lavoro.
</testo_normale>
<testo_normale>
L'interfaccia più semplice fornita da <strong>codecs</strong> è un'alternativa alla funzione built-in <code>open()</code>. La nuova versione funziona proprio come quella built-in, ma aggiunge due nuovi argomenti per specificare la codifica e la tecnica di gestione errori desiderata.
</testo_normale>
<py_code>
# codecs_open_write.py
</py_code>
<testo_normale>
Questo esempio inizia con una stringa <code>unicode</code> con "ç" e salva il testo in un file usando una codifica specificata da riga di comando.
</testo_normale>
<py_output>
$ python3 codecs_open_write.py
</py_output>
<testo_normale>
Leggere i dati con <code>open()</code> è lineare, con una avvertenza: la codifica deve essere conosciuta in anticipo, per poter impostare il decodificatore correttamente. Alcuni formati di dati tipo XML, specificano la codifica come parte del file, ma in genere spetta all'applicazione questa gestione. <strong>codecs</strong> riceve semplicemente la codifica come argomento ed assume che sia corretta.
</testo_normale>
<py_code>
# codecs_open_read.py
</py_code>
<testo_normale>
Questo esempio legge i file creati dall'esempio precedente, e stampa alla console la rappresentazione dell'oggetto <code>unicode</code> risultante
</testo_normale>
<py_output>
$ python3 codecs_open_read.py
</py_output>
<titolo_2>
Ordine dei Byte
</titolo_2>
<testo_normale>
Le codifiche multi-byte tipo UTF-16 ed UTF-32 pongono un problema quando si devono trasferire dati da diversi sistemi, sia copiando direttamente il file che tramite comunicazione di rete. Sistemi diversi utilizzano ordinamenti diversi dei byte alti e bassi. Questa caratteristica dei dati, nota come <a href='https://www.wikiwand.com/it/Ordine_dei_byte' target='_blank'>endianness</a>  dipende da fattori tipo l'architettura hardware e le scelta fatte dal sistema operativo e dagli sviluppatori dell'applicazione. Non sempre è noto in anticipo quale ordine di byte usare per un certo insieme di dati, quindi le codifiche multi-byte includono un marcatore di ordine di byte (BOM) come primi byte dell'output codificato. Ad esempio, UTF-16 è definito in modo tale che 0xFFFE e 0xFEFF non sono caratteri validi, e possono essere usati per indicare l'ordine di byte. <strong>codecs</strong> definisce costanti per i marcatori BOM usati da UTF-16 ed UTF-32.
</testo_normale>
<py_code>
# codecs_bom.py
</py_code>
<testo_normale>
<code>BOM</code>, <code>BOM_UTF16</code> e <code>BOM_UTF32</code> sono automaticamente impostati per utilizzare gli appropriati valori big-endian o little-endian a seconda dell'ordine dei byte nativo del sistema operativo.
</testo_normale>
<py_output>
$ python3 codecs_bom.py
</py_output>
<testo_normale>
L'ordinamento dei byte viene rilevato e gestito automaticamente dai decodificatori in <strong>codecs</strong>, ma può essere specificato un ordinamento esplicito nella codifica.
</testo_normale>
<py_code>
# codecs_bom_create_file.py
</py_code>
<testo_normale>
<code>codecs_bom_create_file.py</code> è in grado di rilevare l'ordinamento dei byte nativo, poi usa la forma alternativa esplicita in modo che l'esempio successivo possa dimostrare l'auto rilevamento durante la lettura.
</testo_normale>
<py_output>
$ python3 codecs_bom_create_file.py
</py_output>
<testo_normale>
<code>codecs_bom_create_detection.py</code> non specifica un ordine di byte all'apertura del file, quindi il decodificatore usa il valore BOM nei primi due byte del file per determinarlo.
</testo_normale>
<py_code>
# codecs_bom_detection.py
</py_code>
<testo_normale>
Visto che i primi due byte del file sono usati per il rilevamento dell'ordine dei byte, non sono inclusi nei dati ritornati da <code>read()</code>.
</testo_normale>
<py_output>
$ python3 codecs_bom_detection.py
</py_output>
<titolo_2>
Gestione degli Errori
</titolo_2>
<testo_normale>
La sezione precedente evidenziava la necessità di sapere in anticipo la codifica utilizzata durante la lettura e scrittura di file Unicode. Impostare correttamente la codifica è importante per due ragioni. Se la codifica è configurata nel modo sbagliato durante la lettura di un file, i dati saranno male interpretati a potrebbero corrompersi o semplicemente fallirebbe la codifica. Non tutti i caratteri Unicode possono essere rappresentati in utte le codifiche; alla stessa stregua una errata codifica in scrittura potrebbe generare errori e perdita di dati.
</testo_normale>
<testo_normale>
<strong>codecs</strong> usa le stesse cinque opzioni di gestione errore fornite dai metodi encode() di str e decode() di bytes, elencati di seguito:
</testo_normale>
<tabella_normale>
MODALITA' ERRORE;DESCRIZIONE
<code>strict</code>;Solleva una eccezione se i dati non possono essere convertiti.
<code>replace</code>;Sositituisce con un carattere speciale marcatore i dati che non possono essere codificati
<code>ignore</code>;Ignora i dati
<code>xmlcharrefreplace</code>;Carattere XML (solo in codifica)
<code>backslashreplace</code>;Sequenza di escape (solo in codifica)
</tabella_normale>
<titolo_>
Codificare Errori
</titolo_>
<testo_normale>
La condizione di errore più comune è ricevere un errore <code>UnicodeEncodeError</code> quando si scrivono dati Unicode in un canale di uscita ASCII, tipo un normale file oppure <cede>sys.stdout</cede> senza un insieme di codifica robusto. Il programma di esempio seguente può essere usato per sperimentare le diverse modalità di gestione errori.
</testo_normale>
<py_code>
# codecs_encode_error.py
</py_code>
<testo_normale>
Sebbene la modalità <code>strict</code> sia la più sicura per assicurarsi che un'applicazione imposti esplicitamente la codifica corretta per tutte le operazioni di I/O, potrebbe condurre a blocchi dei programmi quando viene sollevata una eccezione.
</testo_normale>
<py_output>
$ python3 codecs_encode_error.py
</py_output>
<testo_normale>
Alcune delle altre modalità di gestione errore sono più flessibili. Ad esempio <code>replace</code> assicura che nessuna eccezione viene sollevata, a scapito di possibili perdite dei dati che non possono essere convertiti nella codifica richiesta. Il carattere Unicode per la cediglia non può essere codificato in ASCII, ma viene sostituito nel risultato da un <code>?</code> senza generare errori.
</testo_normale>
<py_output>
$ codecs_encode_error.py replace
</py_output>
<testo_normale>
Per non avere interamente a che fare con problemi di dati si usi <code>ignore</code>. Tutti i dati che non possono essere codificati sono ignorati.
</testo_normale>
<py_output>
$ python3 codecs_encode_error.py ignore
</py_output>
<testo_normale>
Ci sono due opzioni di gestione errori senza perdita di dati, entrambe prevedono la sostituzione del carattere con una sua rappresentazione alternativa definita da uno standard a parte rispetto alla codifica, <code>xmlcharrefreplace</code> utilizza un riferimento di carattere XML come sostituto (la lista dei caratteri è specificata nel documento <em>W3C XML Entity Definitions for Characters)</em>.
</testo_normale>
<py_output>
$ python3 codecs_encode_error.py xmlcharrefreplace
</py_output>
<testo_normale>
L'altro schema di gestione errore senza perdita di dati è <code>bachslashreplace</code> che produce un risultato in uscita come il valore ritornato chiamando <code>repr()</code> su di un oggetto <code>unicode</code>. I caratteri Unicode sono sostituiti da \u seguito dal valore esadecimale del code point.
</testo_normale>
<py_output>
$ python3 codecs_encode_error.py backslashreplace
</py_output>
<titolo_2>
Errori di Decodifica
</titolo_2>
<testo_normale>
E' possibile incorrere in errori durante la decodifica dei dati, specialmente se è usata la codifica sbagliata.
</testo_normale>
<py_code>
# codecs_decode_error.py
</py_code>
<testo_normale>
Come per la codifica, la modalità di gestione errore <code>strict</code> solleva una eccezione se il flusso di byte non può essere decodificato propriamente. In questo caso un <code>UnicodeDecodeError</code> viene generato tentando di convertire parte del BOM UTF-16 in un carattere usando il decodificatore UTF-8.
</testo_normale>
<py_output>
$ python3 codecs_decode_error.py strict
</py_output>
<testo_normale>
Passare alla modalità <code>ignore</code> fa sì che il decodificatore ignori i byte non validi. Il risultato comunque non è ancora quello atteso, visto che vengono inclusi byte nulli.
</testo_normale>
<py_output>
$ python3 codecs_decode_error.py replace
</py_output>
<titolo_2>
Traduzioni in Codifica
</titolo_2>
<testo_normale>
Sebbene la maggior parte delle applicazioni internamente lavora con dati <code>str</code>, la decodifica o codifica è parte di una operazione di I/O; ci sono volte nelle quali modificando la codifica di un file senza passare per quel formato dati intermedio è utile. <code>EncodedFile()</code> riceve un file handle di apertura usando una codifica e lo incapsula in una classe che trascodifica i dati in un'altra codifica quando si verifica una operazione I/O.
</testo_normale>
<py_code>
# codecs_encodedfile.py
</py_code>
<titolo_2>
Codifiche Non Unicode
</titolo_2>
<testo_normale>
Sebbene la maggior parte degli esempi precedenti utilizza codifiche Unicode, codecs può essere usato per molti altri tipi di trascodifiche. Ad esempio Python comprende codec per lavorare con i formati dato base-64, bzip2, ROT-13, ZIP e altri.
</testo_normale>
<py_code>
# codecs_rot13.py
</py_code>
<testo_normale>
Qualsiasi trasformazione che possa essere espressa come una funzione che riceve un singolo argomento e ritorna una stringa Unicode o byte può essere registrata come un codec. Ad esempio per il codec '<code>rot_13</code>', l'input dovrebbe essere una stringa Unicode e l'output sarà anch'esso una stringa Unicode.
</testo_normale>
<py_output>
$ python3 codecs_rot13.py
</py_output>
<testo_normale>
Utilizzando <strong>codecs</strong> per impacchettare un flusso di dati si ha a disposizione una interfaccia più semplice che lavorare direttamente con <a href="zlib.html">zlib</a>.
</testo_normale>
<py_code>
# codecs_zlib.py
</py_code>
<testo_normale>
Non tutti i tipi di compressione o sistemi di codifica supportano la lettura di una porzione di dati attraverso l'interfaccia del flusso usando <code>readline()</code> oppure <code>read()</code> visto che occorre trovare la fine di un segmento compresso per espanderlo. Se un programma può contenere l'intero insieme di dati non compressi in memoria, si utilizzino le caratteristiche di accesso incrementale della libreria di compressione invece di <strong>codecs</strong>.
</testo_normale>
<py_output>
$ python3 codecs_zlib.py
</py_output>
<titolo_2>
Codifica Incrementale
</titolo_2>
<testo_normale>
Alcune delle codifiche fornite, specialmente <code>bz2</code> e <code>zlib</code> potrebbero modificare considerevolmente la lunghezza del flusso di dati durante la lavorazione. Per insiemi di dati molto grandi, queste codifiche operano meglio in modalità incrementale, lavorando su piccole porzioni di dati alla volta. Le API <code>IncrementalEncoder</code> e <code>IncrementalDecoder</code> sono progettate a questo scopo.
</testo_normale>
<py_code>
# codecs_incremental_bz2.py
</py_code>
<testo_normale>
Ogni volta che dati sono passati al codificatore o decodificatore viene aggiornato il proprio stato interno. Quando lo stato interno è consistente (così come definito dal codec), i dati sono restituiti e lo stato viene reimpostato. Fino a quel punto le chiamate a <code>encode()</code> o <code>decode()</code> non ritorneranno alcun dato. Quando l'ultimo bit di dati è stato ricevuto, l'argomento <code>final</code> dovrebbe essere impostato a <code>True</code> in modo che il codec sappia come far fuoriuscire i dati rimasti nel proprio buffer.
</testo_normale>
<py_output>
$ python3 codecs_incremental_bz2.py
</py_output>
<titolo_2>
Dati Unicode e la Comunicazione in Rete
</titolo_2>
<testo_normale>
I socket di rete sono flussi di byte, e a differenza dei flussi standard in input ed output non supportano òa codifica nella modalità predefinita. Questo significa che i programmi che vogliono inviare o ricevere dati Unicode tramite una rete devono codificarli in byte prima di scriverli in un socket. Questo server ripete i dati che riceve al mittente.
</testo_normale>
<py_code>
# codecs_socket_fail.py
</py_code>
<testo_normale>
Si sarebbe potuto codificare esplicitamente i dati prima di ogni chiamata a <code>send()</code>, ma la mancanza di una chiamata a <code>send()</code> avrebbe generato un errore di codifica.
</testo_normale>
<py_output>
$ python3 codecs_socket_fail.py
</py_output>
<testo_normale>
Si usi <code>makefile()</code> per ottenere un handle di tipo file per il socket, quindi lo si impacchetti in un lettore o scrittore basato su flusso, il che fa sì che le stringhe Unicode siano codificate durante l'entrata e l'uscita dal socket.
</testo_normale>
<py_code>
# codecs_socket.py
</py_code>
<testo_normale>
Questo esempio usa <code>PassThrough</code> per mostrare come i dati siano codificati prima di essere inviati, e come la risposta sia decodificata dopo che è stata ricevuta nel client.
</testo_normale>
<py_output>
$ python3 codecs_socket.py
</py_output>
<titolo_2>
Definire un Codec Personalizzato
</titolo_2>
<testo_normale>
Visto che Python è già fornito id un gran numero di codecs standard, è improbabile che un'applicazione debba definire un codificatore o decodificatore personalizzato. Quando è necessario, tuttavia, ci sono parecchie classi base in <strong>codecs</strong> che facilitano il processo.
</testo_normale>
<testo_normale>
Il primo passo è di capire la natura della trasformazione descritta dal codificatore. Questi esempi usano una codifica "inverticaps", che converte le lettere maiuscole in minuscole e viceversa. Ecco una semplice definizione di una funzione di codifica che esegue questa trasformazione data una stringa in input.
</testo_normale>
<py_code>
# codecs_invertcaps.py
</py_code>
<testo_normale>
In questo caso il codificatore ed il decodificatore sono la stessa funzione (così come nel caso con <code>ROT-13</code>).
</testo_normale>
<py_output>
$ python3 codecs_invertcaps.py
</py_output>
<testo_normale>
Sebbene sia facile da comprendere, questa implementazione non è efficiente, specialmente per stringhe di testo molto grandi. Fortunatamente <strong>codecs</strong> comprende alcune funzioni di convenienza per creare codecs basati su <em>mappe di caratteri</em> tipo inverticaps. Una codifica di un mappa di caratteri è composta da due dizionari. La <em>mappa di codifica</em> converte i valori dei caratteri dalla stringa in input in valori byte in uscita e la <em>mappa di decodifica</em> funziona all'opposto. Prima si crea la mappa di decodifica, pui si usa <code>make_encoding_map()</code> per converirla in una mappa di codifica. Le funzioni C <code>charmap_encode()</code> e <code>charmap_decode()</code> usano le mappe per convertire i propri dati in input efficientemente.
</testo_normale>
<py_code>
# codecs_invertcaps_charmap.py
</py_code>
<testo_normale>
Sebbene le mappe di codifica e decodifica a per inverticaps siano le stesse, potrebbe non essere sempre il caso. <code>make_encoding_map()</code> rileva situazioni dove più di un carattere in input è codificato con lo stesso byte in output e sostituisce il valore di codifica con <code>None</code> per marcare la codifica come indefinita.
</testo_normale>
<py_output>
$ python3 codecs_invertcaps_charmap.py
</py_output>
<testo_normale>
La mappa di caratteri di codifica e decodifica supporta tutti i metodi standard di gestione errori descritti in precedenza, quindi non è necessario lavoro supplementare per conformarsi a quella parte dell'API.
</testo_normale>
<py_code>
# codecs_invertcaps_error.py
</py_code>
<testo_normale>
Visto che il code point Unicode per il pi greco non è nella mappa di codifica, la modalità di gestione dell'errore strict solleva una eccezione.
</testo_normale>
<py_output>
$ python3 codecs_invertcaps_error.py
</py_output>
<testo_normale>
Dopo che le mappe di codifica e decodifica sono state definite, occorre impostare qualche altra classe, e la codifica dovrebbe essere registrata. <code>register()</code> aggiunge una funzione di ricerca al registro in modo che quando un utente vuole usare la codifica, <strong>codecs</strong> può localizzarla. La funzione di ricerca deve ricevere una singola stringa come argomento con il nome della codifica, e ritornare un oggetto <code>CodecInfo</code> se la codifica è nota, oppure <code>None</code> in caso contrario.
</testo_normale>
<py_code>
# codecs_register.py
</py_code>
<testo_normale>
Possono essere registrate multiple funzioni di ricerca, ciascuna della quali sarà chiamata a turno fino a che una ritorna un <code>CodecInfo</code> oppure la lista viene esaurita. La funzione di ricerca interna registrata da <strong>codecs</strong> sa come caricare i codec standard, tipo UTF-8 da <code>encodings</code>, in modo che questi nomi non saranno mai passati alle funzioni di ricerca personalizzate.
</testo_normale>
<py_output>
$ python3 codecs_register.py
</py_output>
<testo_normale>
L'istanza di <code>CodecInfo</code> ritornata dalla funzione di ricerca dice a <strong>codecs</strong> come codificare e decodificare usando tutti i diversi meccanismi supportati: stateless, incrementali e stream. <strong>codecs</strong> include classi base per aiutare nell'impostazione di una mappa di caratteri di codifica. Questo esempio mette insieme tutti i pezzi per registrare una funzione di ricerca che ritorna una istanza di <code>CodecInfo</code> configurata per il codec inverticaps.
</testo_normale>
<py_code>
# codecs_invertcaps_register.py
</py_code>
<testo_normale>
La classe base per il codificatore/decodificatore stateless è <code>Codec</code>. Si sovrascrivono <code></code>encode()</code> e <code>decode()</code> con una nuova implementazione (in questo caso, chiamando <code>charmap_encode()</code> e <code>charmap_decode()</code> rispettivamente). Ciascun metodo deve ritornare una tupla che contiene i dati trasformati e il numero di byte in input o caratteri consumati. Convenientemente, <code>charmap_encode()</code> e <code>charmap_decode()</code> ritornano già quelle informazioni.
</testo_normale>
<testo_normale>
<code>IncrementalEncoder</code> e <code>IncrementalDecoder</code> servono come classi base per le interfacce incrementali. I metodi <code>encode()</code> e <code>decode()</code> delle classi incrementali sono definiti in modo tale che ritornano solo i dati effettivamente trasformati. Ogni informazione circa la gestione del buffer viene mantenuta come stato interno. La codifica inverticaps non necessita di gestire un buffer di dati (usa una mappatura uno-a-uno). Per codifiche che producono un diverso ammontare di output a seconda dei dati in elaborazione, tipo gli algoritmi di compressione, <code>BufferedIncrementalEncoder</code> e <code>BufferedIncrementalDecoder</code> sono classi base più appropriate, visto che gestiscono la porzione non elaborata dell'input.
</testo_normale>
<testo_normale>
Anche a <code>StreamReader</code> e <code>StreamWriter</code> servono i metodi <code>encode()</code> e <code>decode()</code>, visto che ci si attende che ritornino gli stessi valori della versione da <code>Codec</code> è possibile usare l'ereditarietà multipla per questa implementazione.
</testo_normale>
<py_output>
$ python3 codecs_invertcaps_register.py
</py_output>
<vedi_anche>
http://docs.python.org/library/codecs.html|codecs|La documentazione della libreria standard per questo modulo
locale.html|locale|Altri strumenti di localizzazione
socketserver.html|socketserver|Per un esempio più dettagliato di un server che ripete quanto ricevuto si veda il modulo socketserver
https://www.python.org/dev/peps/pep-0100|PEP 100|PEP per l'integrazione di Unicode in Python
https://docs.python.org/3/howto/unicode.html|Unicode HOWTO|La guida ufficiale per l'utilizzo di Unicode con Python
https://docs.python.org/3.0/whatsnew/3.0.html#text-vs-data-instead-of-unicode-vs-8-bit|Text vs. Data instead of Unicode vs. 8-bit|Articolo per Python 3.0 nella sezione "What's new" che tratta le modifiche nella gestione del testo.
http://effbot.org/zone/unicode-objects.htm|Python Unicode Objects|Articolo di Fredrik Lundh circa l'uso di insiemi di caratteri non ASCII in Python 2.0.
http://evanjones.ca/python-utf8.html|How to Use UTF-8 with Python|Veloce guida di Evan Jones per lavorare con Unicode, inclusi dati XML e Byte-Order Marker.
http://www.tbray.org/ongoing/When/200x/2003/04/06/Unicode|On the Goodness of Unicode|Introduzione alla internazionalizzazione ed Unicode di Tim Bray.
http://www.tbray.org/ongoing/When/200x/2003/04/13/Strings|On Character Strings|Uno sguardo alla storia dell'elaborazione di stringhe nei linguaggi di programmazione, di Tim Bray.
http://www.tbray.org/ongoing/When/200x/2003/04/26/UTF|Characters vs. Bytes|Prima parte del saggio "essay on modern character string processing for computer programmers". Tratta la rappresentazione in memoria del testi in formati diversi dai byte ASCII.
http://www.w3.org/TR/xml-entity-names/|Characters vs. Bytes|W3C XML Entity Definitions for Characters|Specifiche per la rappresentazione dei riferimenti di carattere che non possono essere rappresentati con una codifica.
</vedi_anche>
</documento_tradotto>
</descrizione>
